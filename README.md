## Olist Eâ€‘Commerce Sales Forecasting Pipeline
Endâ€‘toâ€‘end time series forecasting pipeline built using Python, Prophet, and Tableau, designed to predict daily eâ€‘commerce sales for the Olist marketplace.
This project demonstrates a productionâ€‘style workflow with modular code, clean ETL, automated forecasting, and interactive BI dashboards.

##  Executive Summary
Eâ€‘commerce businesses rely heavily on accurate demand forecasting to optimize inventory, logistics, staffing, and marketing.
This project builds a fully modular forecasting pipeline that:
- Ingests and cleans raw Olist marketplace data
- Engineers timeâ€‘series features
- Trains a Prophet forecasting model
- Evaluates performance using industryâ€‘standard metrics
- Exports forecast outputs for visualization
- Powers an interactive Tableau dashboard for business insights
The result is a scalable, reproducible forecasting system suitable for realâ€‘world analytics workflows

## Architecture Overview

flowchart LR
    A[Raw Olist Data] --> B[Ingestion]
    B --> C[Cleaning & Preprocessing]
    C --> D[Feature Engineering]
    D --> E[Prophet Modeling]
    E --> F[Evaluation]
    F --> G[Export Forecasts
    G --> H[Tableau Dashboard]


##  Dataset: Olist Brazilian Eâ€‘Commerce Public Dataset
This project uses the wellâ€‘known Olist dataset, containing multiple relational tables:
orders : Order -level details with timestamps 
order_items : product-level details per order
products : Prodeuct category metadata
customers : Customer demographies
sellers : Seller information
payments : Payment methods and values
reviews : Customer review scores
The pipeline aggregates these into a daily sales time series.

##  Pipeline Components
1. Ingestion
- Load raw CSVs
- Merge relational tables
- Create unified order-level dataset
2. Cleaning & Preprocessing
- Handle missing values
- Remove duplicates
- Convert timestamps
- Standardize column formats
3. Feature Engineering
- Aggregate daily sales
- Create lag features
- Rolling averages
- Optional: holiday effects
4. Modeling (Prophet)
- Train/test split
- Prophet model with:
- Trend
- Weekly seasonality
- Yearly seasonality
- Hyperparameter tuning
- Forecast generation
5. Evaluation
- Metrics:
- MAE
- RMSE
- MAPE
- Baseline vs Prophet comparison
6. Export
- Save forecast results to /export/
- Output CSV used in Tableau dashboard

ğŸ“Š Tableau Dashboard
The dashboard visualizes:
- Historical sales trends
- Forecasted sales
- Seasonality patterns
- Category-level insights
- Interactive filters
ğŸ‘‰ Dashboard Link: (Tableau Public link here)
ğŸ‘‰ Screenshots: <img width="1487" height="822" alt="image" src="https://github.com/user-attachments/assets/ad351136-c418-457f-9746-67d01012a51a" />



ğŸ›  Tech Stack
- Python
- pandas, NumPy
- Prophet
- Matplotlib / Seaborn
- Tableau
- Git & Terminal workflow

â–¶ï¸ How to Run the Pipeline
1. Clone the repository
git clone https://github.com/aswathappaswetha-tech/Olist-E-Commerce-Sales-Forecasting-Pipeline
cd Olist-E-Commerce-Sales-Forecasting-Pipeline

î·™î·š
2. Install dependencies
pip install -r requirements.txt


3. Run the pipeline
python src/main.py


4. View outputs
- Cleaned data â†’ /data/processed/
- Forecast results â†’ /export/forecasts.csv
- Tableau-ready dataset â†’ /export/tableau/

ğŸ“ Folder Structure
Olist-E-Commerce-Sales-Forecasting-Pipeline/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ cleaning/
â”‚   â”œâ”€â”€ feature_engineering/
â”‚   â”œâ”€â”€ modeling/
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ export/
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ tableau_files/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore



ğŸ“ˆ Business Insights
Key insights derived from the Olist dataset:
- Strong weekly and yearly seasonality
- Sales spikes around holidays
- Long-tail distribution of product categories
- Forecasts help optimize:
- Inventory planning
- Delivery logistics
- Marketing campaigns
- Seller performance management

ğŸ”® Future Improvements
- Add ARIMA / XGBoost forecasting models
- Build automated retraining pipeline
- Add Docker containerization
- Deploy API endpoint for real-time forecasts
- CI/CD with GitHub Actions











    
